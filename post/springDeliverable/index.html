<!DOCTYPE html>
<html>
<head>
    <meta charset="utf-8">
    <title>Systematization and Project Roadmap // Line Of Trust</title>

    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
    <meta property="og:title" content="Systematization and Project Roadmap" />
<meta property="og:description" content="" />
<meta property="og:type" content="website" />
<meta property="og:locale" content="en_US" />
<meta property="og:url" content="https://lineoftrust.github.io/post/springdeliverable/" />


    <link href="" rel="alternate" type="application/rss+xml" title="Line Of Trust" />
    <link rel="shortcut icon" href="/favicon.png">

    <link href="https://lineoftrust.github.io/webfonts/ptserif/main.css" rel='stylesheet' type='text/css'>
    <link href="https://lineoftrust.github.io/webfonts/source-code-pro/main.css" rel="stylesheet" type="text/css">

    <link rel="stylesheet" href="https://lineoftrust.github.io/css/style.css">

    <link href="http://gmpg.org/xfn/11" rel="profile">
    <meta http-equiv="content-type" content="text/html; charset=utf-8">

    
    <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1">

    <meta name="description" content="">
    <meta name="keywords" content="">
    <meta name="author" content="">

    <meta name="generator" content="Hugo 0.20.2" />
</head>


<body>
<div id="container">
    <header id="header">
    <div id="header-outer" class="outer">
        <div id="header-inner" class="inner">
            <a id="main-nav-toggle" class="nav-icon" href="javascript:;"></a>
            <a id="logo" class="logo-text" href="https://lineoftrust.github.io/">Line Of Trust</a>
            <nav id="main-nav">
                
            </nav>
            <nav id="sub-nav">
                <div id="search-form-wrap">
                </div>
            </nav>
        </div>
    </div>
</header>
    <section id="main" class="outer">
        <article class="article article-type-post" itemscope itemprop="blogPost">
    <div class="article-inner">
        
        <header class="article-header">
            <h1 class="article-title" itemprop="name">Systematization and Project Roadmap</h1>
        </header>
        
        <div class="article-meta">
            <a href="/post/springdeliverable/" class="article-date">
                <time datetime='2017-05-02T14:40:06.000-04:00' itemprop="datePublished">2017-05-02</time>
            </a>
            
            
            <div class="post-categories">
                <div class="article-category">
                    
                    
                    <a class="article-category-link" href="https://lineoftrust.github.io//categories/project-update">project update</a>
                    
                </div>
            </div>
            
            
        </div>
        <div class="article-entry" itemprop="articleBody">
            

<h1 id="spring-deliverable">Spring Deliverable</h1>

<p>As part of the <a href="http://virginia.edu" target="_blank">University of Virginia</a>&rsquo;s Spring 2017 <a href="https://tlseminar.github.io/" target="_blank">graduate seminar
on Transport Layer Security (TLS)</a>, our project
team has continued to investigate modern issues surrounding usable privacy and
security of web browsing.
The Line of Trust project seeks to understand the security, privacy, and human-factors related to a class of phishing
and picture-in-picture attacks known collectively as the <a href="https://textslashplain.com/2017/01/14/the-line-of-death/" target="_blank">Line of Death</a>.
Contextualizing relevant literature and systematically analyzing the underlying
problems in the Line of Death space will contribute to a Systematization of
Knowledge (SoK) paper, which we intend to augment with a thoughtful user study.
The goal of this blog post is to present the culmination of our work throughout the last
six weeks of the semester and provide a roadmap for our team&rsquo;s plans to move
forward through the summer months.</p>

<h1 id="presentation">Presentation</h1>

<script async class="speakerdeck-embed"
data-id="710bc0557e1240d9a9d209d1ed14ddde" data-ratio="1.33333333333333"
src="//speakerdeck.com/assets/embed.js"></script>

<p><a href="https://tlseminar.github.io/" target="_blank">TLSeminar</a>&rsquo;s mini-conference provided our team
the opportunity to motivate and present our project work during the latter half
of the semester. Our presentation (above) focused on describing the research
problem through a case study of an elaborate picture-in-picture <a href="https://www.tripwire.com/state-of-security/latest-security-news/tech-support-scam-uses-website-elements-spoof-microsoft-support-page/" target="_blank">Microsoft Support Webpage
Scam</a>
reported in March 2017.</p>

<h1 id="introduction">Introduction</h1>

<p>The state of web browser client UI today is best described as a disjoint medley of vulnerabilities, contradictory design principles, and implied security conditions.  Apart from the overarching design paradigm of a URL bar perched above page content with a tab-interface situated nearby, almost all aspects of contemporary web browsers vary from one vendor to the next.  There exist no universal security indicators, nor are the relative levels of security—think mixed HTTPS vs full HTTPS—ever explicitly presented to consumers of these products.  Warning prompts, pop-ups, and alerts are all handled differently.  Settings are difficult to find.  Extensive assortments of flags, optional settings, and advanced content featuers are tucked away far beneath the visible surface of the browser interface.</p>

<p>This industry-wide abuse of basic UI principles has resulted in a number of frightening security implications for everday users—issues that have largely gone unaddressed in the security community for the past decade.  Though major vendors like Google (developer of the Chromium project and the Chrome web browser) have taken steps to address some of the more sophisticated UI security issues plaguing web browsers, much more must be done to provide a sense of security for the vast majority of average Internet users who are most vulnerable.</p>

<p>This post is the result of six weeks of brainstorming, reading, contemplating, presenting, and discussing web browser UI security.  In it, we seek to provide a framework to systematize current and proposed approaches aimed at improving web browser client UI, venturing as far as offering a few suggestions of our own.</p>

<p>Before we delve into that, however, some motivation is in order.</p>

<h2 id="the-line-of-death">The Line of Death</h2>

<p>In January of this year, Eric Lawrence, writing for <em>text/plain</em>, published an <a href="https://textslashplain.com/2017/01/14/the-line-of-death/" target="_blank">article</a> about an intriguing concept he coined the &ldquo;Line of Death&rdquo; that demarcates trusted from untrusted content in a web browser.  Consider the image below.</p>

<p><img src="https://textplain.files.wordpress.com/2017/01/image36.png?w=1440&amp;h=584" alt="The Line of Death (text/plain)" title="The Line of Death" /></p>

<p>As you can see, the page, <em>www.example.com</em>, exercises full control over the content below the red dotted line—the &ldquo;line of death.&rdquo;  Consequently, as a user, you should not trust anything below this line that appears to be imitating a legitimate browser function.  For example, consider a malicious page attempting to redirect you to a spyware site.  The page may generate a fake element that looks like a generic &ldquo;alert&rdquo; box, but since it appears below the line of death, the user should assume that it may be fake and thus refrain from clicking.  As one would imagine, this notion is problematic—<em>real</em> alert boxes actually <em>do</em> appear in the untrusted page content!  How are average users expected to differentiate between legitimate alerts hovering <em>above</em> the browser window and fake alerts displayed <em>within</em> the browser window?  Making matters worse, malicious developers can even deploy JQuery scripts that cause their fake alert boxes to mimic the UI functionality of legitimate boxes—click and drag, &ldquo;cancel,&rdquo; etc.  This mimicry is not limited to alert boxes; page elements such as download prompts, microphone/camera permission prompts, and plugin prompts are all vulnerable to imitation.</p>

<p>We can extend this basic line of death example even further by imaging a scenario in which the <em>entire trusted UI</em> —tab bar, URL bar, bookmarks, HTTPS status—are spoofed within the untrusted content area.  <em>But that would be so obvious</em>, you exclaim!  Well, as we shall see, this so-called &ldquo;picture-in-picture&rdquo; attack is most potent when the user enters full-screen mode, wherein the trusted UI portion disappears from view to provide the user with more screen space.  An unsuspecting user could <em>easily</em> forget that a URL bar should not be present and simply trust the URL bar and security indicators that happen to be dispalyed in the spoofed UI.  For example, in the image below, the entire legitimate, trusted browser UI one would expect to see while visiting PayPal.com is spoofed and displayed <em>inside the untrusted content area</em>.</p>

<p><img src="https://textplain.files.wordpress.com/2017/01/image40.png?w=1516&amp;h=982" alt="Picture-in-Picture Attack (text/plain)" title="Picture-in-Picture" /></p>

<h2 id="certified-malice">Certified Malice</h2>

<p>In a <a href="https://textslashplain.com/2017/01/16/certified-malice/" target="_blank">follow-up piece</a> to <em>Line of Death</em> published only two days following the original article, Eric Lawrence presented another, more insidious browser UI weakness:  malicious websites can just as easily acquire HTTPS certificates as legitimate websites.  This so-called &ldquo;certified malice&rdquo; renders the identification of illegitimate spoofing sites nearly impossible.  In this threat model, phishing sites attempting to masquerade as legitimate sites &ldquo;secure&rdquo; their pages with HTTPS certificates, leading users— <em>generations of whom have been trained to trust the green lock</em> —to believe the malicious site is &ldquo;good.&rdquo;  (We cannot help but point out the obvious irony:  HTTPS certificate proliferation helps the bad guys, too!)</p>

<p>Clearly, this intricate web of UI, security, and social engineering issues necessitates attention to ensure average web browsers do not go astray attempting to check email online.  The two articles referenced above were published <em>less than four months ago</em> and represent the <em>only</em> contemporary inquiries into web browser UI problems.  In fact, it seems that most serious academic work in this area ceased about ten years ago.  This abrupt end to the study of web phishing attacks could mean one of three things:</p>

<ol>
<li>Web phishing is a hard problem with few clear answers, therefore it&rsquo;s difficult to be published, hence the lack of published papers.</li>
<li>No one cares about web phishing anymore.  It&rsquo;s not cool.</li>
<li>The research community has been focusing on other pursuits in the past decade but would certainly investigate these issues if given a friendly reminder.</li>
</ol>

<p>We maintain a firm belief in option #3, and in the potential for future investigation and academic work.  This systematization and roadmap seeks to codify that belief.</p>

<h1 id="systematization">Systematization</h1>

<h2 id="overview">Overview</h2>

<p>Our systematization follows a uniform process that enables us to categorize, assess, and ultimately rate the potential usefulness of various research works and related resources.  In it, we attempt to address the following issues:</p>

<ol>
<li><strong>What problem(s) does the resource address?</strong><br /></li>
<li><strong>Does the problem relate to web browser UI? If so, how?</strong> What aspects of the problem are shared between the resource topic and web browser UI?</li>
<li><strong>What solution(s) is proposed?</strong></li>
<li><strong>Are the solutions relevant to web browser UI? If so, how?</strong>  What aspects of the solution(s) could be applied to web browser UI?</li>
<li><strong>What are the pros and cons of the solutions with respect to security, usability, and ease of adoption?</strong>  Will people use it?  What security guarantees are implied?  How likely is it that users will actually interact with the solution mechanism?</li>
<li>[if viable] <strong>Based on the resource, how would you suggest proceeding with the implementation of the solution?</strong></li>
</ol>

<h2 id="paper-1">Paper 1</h2>

<p>TODO: Perform the systematization analysis on each paper you have read using our
methodology as described aboce.</p>

<h2 id="a-trused-ui-for-the-mobile-web">A Trusted UI for the Mobile Web (2014)</h2>

<p>The population increasingly relies on mobile devices to browse the web. However, though mobile devices come with increased security concerns, the literature in this space is shockingly sparse. Braun et al. attempts to classify and target a set of major threats to browser security: phishing, clickjacking, CSRF, XSS, and session fixation. Braun divides these threats into five main classes: phishing, clickjacking, CSRF, XSS, and session fixation. Each attack is unique in its goals or means to achieve them. The goal of a phishing attack is to convince the user to divulge personal information, whereas clickjacking is when an attacker will attempt to force or coerce the user to click on an icon or button. CSRF attacks involve a crafted URL that causes the browser to send a request to the web application on behalf of the user. XSS attackers insert malicious code into otherwise benign websites, this code often runs without prompting. For a session fixation attack to be successful, the attacker sets an SID before logon, then accesses the user’s session simultaneously to the user, impersonating them.</p>

<p>Furthermore, mobile browser security is not only challenged by all of the usual issues faced by full browsers, but also faces additional problems unique to mobile devices. Smaller screen sizes leave less space for visual security indicators. To the point, most major mobile browsers today default to hiding the entire browser bar. This leaves the bare contents of the page unaccompanied by status elements like the site URL, which are vital for users to visually verify the identity of websites. Another important security threat introduced to mobile devices is the user tendency to create shorter, easier-to-type, but less secure passwords, chosen because of clunky, difficult virtual keyboards onboard mobile devices. Finally, “tapjacking” is the mobile variant of clickjacking threats. This is essentially clickjacking on mobile devices; given the limited space on a mobile device, tapjacking can be accomplished by zooming clickable zones even a small amount. Iframe, Apple’s frame-defining software, can be overridden by attackers to achieve this goal.</p>

<p>These threat classes defined by Braun et al. outline the vulnerabilities of web browser user interfaces. Since these threats attack the path between the user and the browser, the burden of responsibility to provide defense is placed on browsers. Thus, to secure users against these relevant threats, it is vital to establish more meaningful user interfaces and exploring thoughtful alternatives to approaching to the way users interact with the web. In particular, keeping users out of the path of danger is primarily important when users are performing authenticated actions online. In these cases, where users are attempting to log into a website with private credentials like usernames and passwords, there is a particular need for a trusted path that verifies the user’s intent in order to convey this sensitive information.</p>

<p>Braun et al. introduce an alternative to entering user credentials directly into browser forms. On mobile devices, when a user tries to perform an authenticated action by accessing a page that requests their credentials, this request is routed through a dedicated app, distinct from the browser application. This app encapsulates user’s credentials and authorization state and maintains a trust relationship with the web server. Once the user passes a security challenge prompted by the app, the user’s authority is passed to the server-side module using a Diffie-Hellman-style shared secret. Thus, the browser app itself never receives, processes, or sends credentials that are used to conduct authorized actions.</p>

<p>While not explicitly discussed by Braun et al., a similar solution could, of course, be implemented on non-mobile browsers through a browser extension or distinct application, as the challenges faced by standard browsers is a strict subset of those faced by mobile browsers. Regardless of the platform, this solution not only creates a trusted path to convey the user’s authority between the user and the web server, but more importantly, addresses the discussed threat classes like phishing or clickjacking. If a user enters an illegitimate page posing as a familiar, trusted site, the authenticator app will not recognize the server’s identity, and thus, will not pass on the user’s credentials.</p>

<p>This proposition does not rely on the web browser user interface to stopgap its persisting problems with more conspicuous alerts or spoofable visual elements. Instead, it augments web browser user interface design by relieving it of the task to relay user authority to the server. In turn, this process bypasses the vulnerabilities that come with sensitive user information being passed through the browser, like phishing attacks. It also does not rely on the user paying attention to visual security alerts produced by the browser or being observant enough to notice a suspicious site posing as another. Furthermore, variations of this solution have already been deployed to the market with great popularity: for example, password managers like LastPass save the user’s credentials in one master account for web and mobile, guarding them with options like two-factor authentication, fingerprint scanning, or a master password. These services also often provide strong password generation, reducing the tendency to reuse passwords or create weak passwords. Overall, this also increases browser usability, allowing users to use more secure passwords without the inconvenience of remembering and retyping them.</p>

<p>More analysis is required with regards to security; new or continuing threats to this proposed solution need to be thoroughly evaluated before its adoption. Whether or not the app request itself is spoofable seems like it would be a significant factor in the potential for adoption. The applications need to be set up in such a way that users still have the ability to enter their credentials on unauthenticated sites if they choose to. We also need to ask moral questions such as: Does requiring a server-side module threaten net neutrality?</p>

<h2 id="trusted-paths-for-browsers">Trusted Paths for Browsers (2002)</h2>

<p>Zishuang attempts to define a system for differentiating content elements, which make up webpages, from status elements, which lie in the browser bar and indicate meta-data like the URL. As it stood at the time of the paper, no significant differentiating feature exists to give users a trusted sense of where a given element is coming from. Users are often tricked by false browser notifications, and providing a way for them to identify true browser notifications would greatly benefit a variety of users.</p>

<p>This inability to distinguish notification sources leaves users susceptible to clickjacking and phishing attacks. Changing the browser UI to signal the users to non-browser notifications appears to be the only way to fix this problem without compromising privacy or disabling useful functionality. Thus we must assume that this is relevant to the way we design browser UI in a significant way. Because of these faults, malicious sites can also cover up potentially important browser elements and trick the user into compromising their security.</p>

<p>Zishuang proposes and attempts to evaluate a variety of potential solutions to this problem. The potential solutions are evaluated on a binary scale based on inclusiveness, effectiveness, minimization of user effort, and minimization of intrusiveness. Respectively, these categories are meant to ensure that the system makes item sources broadly identifiable, usably identifiable, require little effort on the user’s end, and not interrupt or limit the usability. The style selected as most useful by the paper is SRD, or synchronized random dynamic boundaries. SRD was evaluated positively in all four categories.</p>

<p>The general ideas for solutions include preventing collisions between browser and content spaces, similar to the way that we think of information above the line of death to be browser-only. The proposed solutions include no-turnoff, simply preventing features like fullscreen that effectively turn off status elements. This was rejected on the basis that it infringes on a significant amount of content and would be rejected by the internet community.</p>

<p>Another solution hinges on user-specific customized indicators that would require some input from users at browser outset. This was generally found to be somewhat effortful on the user’s end and would lead to problems similar to overused passwords. Users also may not notice or recognize such content (or the lack thereof) in browser/server notifications, so too much of the responsibility is put on the users to be aware of threats. Other efforts also fail based on these same issues, such as metadata titles/windows. In these cases, information would be passed through “safe” means to the users, but still requires that users check for this data before proceeding with anything. The “safe” data spaces would either be in the title, which is subject to picture-in-picture attack, or in a separate browser window, which will likely be ignored altogether.</p>

<p>The CMW approach is discussed in depth, creating a secondary colored browser window below the main window, indicating the safety of page content. Theoretically, by pairing this with the boundary-style solution, users would be able to identify unsafe contents based on inconsistencies between the boundary color and the secondary window color. This was rejected because it requires that the user clicks on the potentially unsafe content before being able to confirm the safety of the content.</p>

<p>SRD is considered a subset of CMW-style solutions. In an SRD-active browser, the border color of the browser and the color of the secondary window would change in a random but synchronized manner. Attackers would not be able to spoof these random changes, and color discrepancies should be relatively easy to identify by users. This does require that both the secondary window and borders be fixed on the screen, visible even when in fullscreen. This proposition represents a family of possible solutions to securing the user interface of web browsers, in which all focus on improving visual security cues in an attempt to enable the user to notice when an illicit third-party attempts to spoof their webpage.</p>

<p>CMW-style solutions and others mentioned in the paper are not easily applicable to mobile devices, though the process for finding solutions remains valid. The primary issues with these solutions is that they expect users to be vigilant and that they are based in the idea that there are pixels on the screen that are in no case accessible to users. Adoption of such a solution is unlikely. Without that assurance, every potential solution is spoofable. While the provided solutions might be viable, user backing is unlikely and implementation issues arise. For instance, Firefox prevents scripts in non-active windows, meaning that the secondary window that provides the reference color in the SRD solution would freeze at its initial color until the user switches windows. This means that the synchronized random color changing would be impossible.</p>

<h2 id="your-attention-please">Your Attention Please (2013)</h2>

<p>Bravo-Lillo et al. address the “boy who cried wolf” problem facing web browser user interfaces. In contemporary browsers, users are inundated with excessive warnings, which, dangerously, desensitizes them to alerts of real risks. When deciding whether to visit insecure sites while browsing, it is essential for browsers to convey security messages that are effective, meaningful, and minimally disruptive. The user study conducted by Bravo-Lillo et al. evaluates the ability of particular types of warning elements to cause users to deviate from their “script”.</p>

<p>The paper presents and assesses five inhibitive attractors, which draw the user’s attention to important details, and either allow time to expire or require user interaction to proceed to the requested action. For example, the site URL might be highlighted in yellow or the user might be required to type the site URL into a dialogue before proceeding to the page. Their effectiveness was then tested in a user study for three different scenarios, and Bravo-Lillo et al. found that among 872 participants, their proposed attractors outperformed the control by up to 50%. These results suggest that alerts that prevent quick warning click-throughs or require user interaction are helpful for preventing users from exposing themselves to security vulnerabilities.</p>

<p>The study captures an important principle of web browser UI design: to avoid strong-arming users out of performing actions which the browser deems unsafe, while still protecting users from themselves. Put plainly, users should be able to do what they choose to do, rather than have this choice taken from them. Thus, it is paramount that browsers enable users to make an educated decision, which requires the browser to provide the user with intelligible security indicators. These messages need to consistently capture the user’s attention and convey the specific, real-life dangers of bypassing the alert.</p>

<p>While the specifics of this particular software implementation studied in this paper are not necessarily directly applicable, implementing similar indicators for user actions would be potentially useful. For example, when typing in a password field, prompting the user to interact with the browser URL in some way could help protect users from phishing attacks. More importantly, the principles of these attractors could be helpful for conveying vital security information to the user, like an insecure site.</p>

<h2 id="you-can't-be-me">You Can't Be Me: Enabling Trusted Paths & User Sub-Origins in Web Browsers (2014)</h2>

<p>Budianto and his team attempt to address scripts that are injected into a web session (malicious scripts included) after the user is authenticated that have complete access to user-owned resources. Budianto et al. focus on defending against post-injection script execution (PISE) attacks. Web applications that provide services to users with accounts (DropBox, Gmail, Facebook) restrict access control using the notion of user authority. Usually, this access is governed by the same-origin policy. However, this is insufficient. Injected scripts appear to the web server to come from the same origin as user input, with the same protocol, host, and port. Thus, server-side web applications cannot distinguish between the real user’s requests and requests generated by scripts.</p>

<p>Web browser user interface is charged with providing a trusted path between the user and the server. Since this stream can be poisoned en route to the server, this is a failure of the browser to guarantee that user authority passed through the browser user interface is not abused by illegitimate third parties. Thus, there is a need for an improvement in the way the web browser user interface handles the user’s authority.</p>

<p>Budianto et al. define user sub-origins as all primitives that run with user authority. Using this concept, they propose User-Path, a protocol that establishes an end-to-end trusted path between web browser users and web servers by isolating the user’s data and privilege from the rest of the web origin. Thus, User-Path tightens the authority of users from the entirety of web sessions to user sub-origins. This is accomplished by refining the web-browser’s user interface by providing a secure tunnel to relay user data to web applications, despite PISE attacks like XSS worms.</p>

<p>Since this solution is a very light extension (less than 500 lines of code), it appears very deployable and easy to adopt. Furthermore, usability remains unaffected - the implementation increases the security of the user’s authority without changing the user’s experience on the front-end. However, this is a limited solution which addresses the particular problem of PISE attacks. User-Path is not a comprehensive defense against all threat classes in the field, but remains an important smaller element of a greater-encompassing solution. </p>

<p>Work towards implementation has been started; Budianto et. al have already developed a Chromium patch. Future work includes extending similar versions to other major browsers and potentially making it a default browser component.</p>

<h2 id="operating-system-framed-in-case-of-mistaken-identity-measuring-the-success-of-web-based-spoofing-attacks-on-os-password-entry-dialogs">Operating System Framed in Case of Mistaken Identity: Measuring the success of web-based spoofing attacks on OS password-entry dialogs</h2>

<p>Today&rsquo;s desktop operating systems often use windows which provide scant evidence
that a trusted path has been established when asking users to enter credentials
(<a href="http://people.cs.georgetown.edu/~clay/classes/spring2013/papers/Operating_System_Framed_in_Case_of_Mistaken_Identity.pdf" target="_blank">Bravo-Lillo, C., et
al.</a>).
This paper attempts to quantify the success rate of web-based spoofing attacks
on OS password-entry dialogs. There is a clear connection between this study and
common Line of Death browser UI attacks, as many of them rely on emulating valid
browser- or OS-level elements to trick users into clicking on links or entering
sensitive credentials. The study validates the efficacy of web-based attacks that
spoof OS windows and presents the challenges of a path forward to trust: &ldquo;proving
that a trusted path ritual will resist real-world attacks requires
deploying the ritual into the hands of users who will
be relying on it to do so. The failures of individual trusted path mechanisms
suggest that the problem is unlikely to be addressed adequately
by any single mechanism. Rather, future work may focus
on rituals that combine mechanisms. For example, consider
rituals in which users must first enter a shared attention sequence
and then expect to see a visual shared secret.&rdquo; There remain significant
usability concerns of any particular trusted path implemented, although it is
clear from the study that is Line of Death attacks are highly successful and
readily feasible on unsuspecting users. See our user study design considerations
for further directions inspired by this study.</p>

<h2 id="guardroid-trusted-path-authentication">GuarDroid (Trusted Path, Authentication)</h2>

<p><a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.480.9704&amp;rep=rep1&amp;type=pdf" target="_blank">GuarDroid</a>
is a system that protects Android user&rsquo;s passwords from untrusted Android apps.
It addresses the problem of establishing a trusted path between the user and
the service that leverages the smartphone operating system as a trusted computing base.
In relation to web browser UI privacy and security, GuarDroid presents a means
to &ldquo;invert&rdquo; the relationship of user authentication to web sites by keeping the Android
operating system accountable for verifying itself to the user; the user is not
intended to trust sensitive input forms that are not protected by GuarDroid&rsquo;s
application overhead, and only to trust GuarDroid&rsquo;s input when presented with
the secret passphrase set prior to the smartphone&rsquo;s system image configuration.
While GuarDroid is designed to leverage security guarantees for untrusted
Android applications and their form data submission to web servers, the
applicability of GuarDroid to a web browser UI (perhaps executed through a
trusted extension or core browser feature) is analogous to the scope of the Line
of Death attacks we consider. The most significant deterrent to using
GuarDroid&rsquo;s trusted path is the usability need for the secret passphrase to be
a human-readable phrase (i.e., low entropy for a guessing adversary) rather than
utilizing random base 64 characters as the secret for verification. The
advantages of implementing a trusted path, however, are quite effective and
serve as a model of a solution to picture-in-picture attacks from the trusted
base of the browser.</p>

<h2 id="rethinking-url-bars-as-primary-browser-ui">Rethinking URL Bars as Primary Browser UI</h2>

<p>In <a href="https://medium.com/@owencm/rethinking-url-bars-as-primary-browser-ui-e2118339d2c0" target="_blank">this work</a>, Google employee Owen Campbell-Moore argues that the browser URL bar provides users with antiquated information and delivers a call-to-action for overhauling browser UI.  This piece is of particular interest to the systematization since it directly addresses browser UI, and the solution proposed—overhauling browser UI by removing the URL bar and replacing it with an <em>origin-to-local-brand-mapping</em> interface—would greatly alter the browser security landscape.  According to Campbell-Moore, URL bars exist to perform three basic tasks:</p>

<ol>
<li>Provide the identity of the site being visited (domain name, title tag)</li>
<li>Indicate relative location in the site organization (path)</li>
<li>Provide an easy-to-share resource link (URL)</li>
</ol>

<p>Tasks (1) and (2) are increasingly unnecessary, since most users rely on search engines, apps, bookmarks, and history to navigate to destination sites.  As a result, there are fewer opportunities to manually provide URLs, and as mobile browsing continues to decimate client browsing, there will be even fewer.  The user’s current path location on websites is used even less, especially given the proliferation of dynamically generated &ldquo;app-like&rdquo; content of Web 2.0.  In fact, Campbell-Moore argues that only (3) is still legitimate, but even that is being replaced by the ubiquitous &ldquo;share&rdquo; buttons connected to various social media entities.</p>

<p><em>Origin-to-local-brand-mapping</em> would operate in a manner similar to DNS or certificates, in that an &ldquo;identity&rdquo; is mapped to a resource, except in this case, the identity would consist of a name and a logo.  The idea would be to <em>only</em> provide this mapping to certain &ldquo;well known&rdquo; web sites, thus avoiding the scenario in which a legitimate site registers for the mapping service.  As a result, it would be very obvious to casual browsers whether they have arrived at the <strong>real</strong> PayPal.com or not, since the <strong>real</strong> PayPal.com will come with an origin-to-local-brand-mapping that clearly signals its legitimacy.</p>

<p>Obvious concerns include the notion of compiling and maintaining a &ldquo;well-known sites&rdquo; index, since at face value, this seems to violate neutrality and place a vast amount of power into one organization’s hands (likely a search engine, likely Google).</p>

<h1 id="deliverable-conclusion-and-project-roadmap">Deliverable Conclusion and Project Roadmap</h1>

<p>In this blog post, we first motivated and described our semester&rsquo;s efforts
towards the Line of Trust project, using our class presentation slides and a
<a href="https://www.tripwire.com/state-of-security/latest-security-news/tech-support-scam-uses-website-elements-spoof-microsoft-support-page/" target="_blank">compelling case
study</a>.
Secondly, we detailed and evaluated our methodology for systematizing research
literature and community blog posts of significance to
 the Line of Death class of attacks.
Thirdly, we coalesced and analyzed a variety of literature according to our
systematization techniques, and constructed general relationships between the class of
problems uncovered in our literature systematization.</p>

<p>As the semester is coming to an end, our plans for the future of the project
are as follows:</p>

<ul>
<li><p>We intend to continue work on the Line of Trust project during the summer
months, with the goal of submitting a qualitative Systematization of Knowledge
research paper to a conference in the fall term.</p></li>

<li><p>Given the difficulties encountered in uncovering reputable, relevant academic work in this particular area of interest, we hope to incorporate more resources into this systematization in order to provide a more holistic view of the state of web browser UI.</p></li>
</ul>

<h2 id="design-considerations-user-study">Design Considerations:  User Study</h2>

<p>Designing a thoughtful user study related to security is not a trivial undertaking.  As <a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.136.5612&amp;rep=rep1&amp;type=pdf" target="_blank">Gaw et al.</a> and <a href="http://www.dourish.com/publications/2004/PUC2004-security.pdf" target="_blank">Dourish et al.</a> argue, user practices related to security need to be understood, yet actually obtaining observational data about the nature of user practices is challenging, since security is rarely interacted with directly.</p>

<p>Qualitative techniques such as interviews and surveys can be successful but have a unique array of limitations—namely, participants exercise heightened vigilance and caution and claim to take particular actions with respect to security that may otherwise be totally different outside the interview.  Thus, the issue of <em>unreliability</em> becomes a limiting factor in the effectiveness of interviews and surveys.  Interestingly, <a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.464.9463&amp;rep=rep1&amp;type=pdf" target="_blank">Whalen and Inkpen</a> note that in a lab study of web browser security, participants didn’t act to protect data and resources as if they were their own, hinting that motivation is another area of concern in hands-on study approaches.</p>

<p>Lastly, the nature of conducting a study on security practices unavoidably introduces bias into the results, since the evaluator must somehow prime the participant to focus specifically on security, as <a href="http://up.csail.mit.edu/projects/phishing/chi-security-toolbar.pdf" target="_blank">Wu et al.</a> note.  Thus, a good security study must make security a peripheral goal rather than a primary goal.</p>

<p>We believe a web browser UI user study must seek to answer a series of questions:</p>

<ol>
<li><p><strong>Can users differentiate legitimate UI from spoofed UI?</strong> To answer this question, users will need to differentiate between fake UI elements generated in the page below the line of death and legitimate UI elements that happen to be overlaid on untrusted content.  Though an outright comparison survey would be useful, many of these spoofing attacks rely on users missing subtle visual cues—cues that they would be highly attuned to while conducting a survey.  As a result, identifying fake versus legitimate UI elements must be a secondary, passive object built into some other test.  In effect, we need to mislead the study participants so that they are’t paying explicit attention to visual UI cues, but instead interacting with them naturally.</p></li>

<li><p><strong>Can users detect picture-in-picture attacks?</strong> A similar approach to (1) is desired here—the users can’t know what is going on.  This would gain added legitimacy if it were tested on both mobile and desktop browsers.</p></li>

<li><p><strong>Do users understand what security or privacy guarantees the green TLS &ldquo;lock&rdquo; icon implies?</strong> How well do web users understand the concept that a malicious page with a secure connection is still malicious?</p></li>
</ol>

<p>The experimental answers to these questions would help us determine whether this is, in fact, a serious problem that users are vulnerable to, rather than a niche phishing concern with little practical relevance in reality.</p>

<h1 id="references">References</h1>

<ul>
<li><a href="https://textslashplain.com/2017/01/14/the-line-of-death/" target="_blank">https://textslashplain.com/2017/01/14/the-line-of-death/</a></li>
<li><a href="https://textslashplain.com/2017/01/16/certified-malice/" target="_blank">https://textslashplain.com/2017/01/16/certified-malice/</a></li>
<li><a href="https://medium.com/@owencm/rethinking-url-bars-as-primary-browser-ui-e2118339d2c0" target="_blank">https://medium.com/@owencm/rethinking-url-bars-as-primary-browser-ui-e2118339d2c0</a></li>
<li><a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.136.5612&amp;rep=rep1&amp;type=pdf" target="_blank">http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.136.5612&amp;rep=rep1&amp;type=pdf</a></li>
<li><a href="https://cups.cs.cmu.edu/soups/2006/proceedings/p133_gideon.pdf" target="_blank">https://cups.cs.cmu.edu/soups/2006/proceedings/p133_gideon.pdf</a></li>
<li><a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.464.9463&amp;rep=rep1&amp;type=pdf" target="_blank">http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.464.9463&amp;rep=rep1&amp;type=pdf</a></li>
<li><a href="http://up.csail.mit.edu/projects/phishing/chi-security-toolbar.pdf" target="_blank">http://up.csail.mit.edu/projects/phishing/chi-security-toolbar.pdf</a></li>
<li><a href="http://www.guanotronic.com/~serge/papers/chi07.pdf" target="_blank">http://www.guanotronic.com/~serge/papers/chi07.pdf</a></li>
<li><a href="https://web.sec.uni-passau.de/papers/2014_Braun_Koestler_Posegga_Johns-Trusted-UI-Mobile-Web.pdf" target="_blank">A Trusted UI for the Mobile Web (2014)</a></li>
<li><a href="http://www.cs.dartmouth.edu/~sws/pubs/ysa05.pdf" target="_blank">Trusted Paths for Browsers (2002)</a></li>
<li><a href="https://cups.cs.cmu.edu/soups/2013/proceedings/a6_Bravo-Lillo.pdf" target="_blank">Your Attention Please (2013)</a></li>
<li><a href="https://www.comp.nus.edu.sg/~jiayaoqi/publications/userpath.pdf" target="_blank">You Can’t Be Me: Enabling Trusted Paths & User Sub-Origins in Web Browsers (2014)</a></li>

</ul>

        </div>

        
        
        <div class="article-toc" >
            <h3>Contents</h3>
            <nav id="TableOfContents">
<ul>
<li><a href="#spring-deliverable">Spring Deliverable</a></li>
<li><a href="#presentation">Presentation</a></li>
<li><a href="#introduction">Introduction</a>
<ul>
<li><a href="#the-line-of-death">The Line of Death</a></li>
<li><a href="#certified-malice">Certified Malice</a></li>
</ul></li>
<li><a href="#systematization">Systematization</a>
<ul>
<li><a href="#overview">Overview</a></li>
<li><a href="#paper-1">Paper 1</a></li>
<li><a href="#paper-2">Paper 2</a></li>
<li><a href="#operating-system-framed-in-case-of-mistaken-identity-measuring-the-success-of-web-based-spoofing-attacks-on-os-password-entry-dialogs">Operating System Framed in Case of Mistaken Identity: Measuring the success of web-based spoofing attacks on OS password-entry dialogs</a></li>
<li><a href="#guardroid-trusted-path-authentication">GuarDroid (Trusted Path, Authentication)</a></li>
<li><a href="#rethinking-url-bars-as-primary-browser-ui">Rethinking URL Bars as Primary Browser UI</a></li>
</ul></li>
<li><a href="#deliverable-conclusion-and-project-roadmap">Deliverable Conclusion and Project Roadmap</a>
<ul>
<li><a href="#design-considerations-user-study">Design Considerations:  User Study</a></li>
</ul></li>
<li><a href="#references">References</a></li>
</ul>
</nav>
        </div>
        
        

        


        
    </div>
    <nav id="article-nav">
    
    
    <a href="/post/update_01/" id="article-nav-older" class="article-nav-link-wrap">
        <div class="article-nav-title">Status Update - Week 2&nbsp;<span>&gt;</span></div>
    </a>
    
</nav>
</article>

        
    </section>
    <footer id="footer">
    <div class="outer">
        <div id="footer-info" class="inner">
            &copy; 2017 Line Of Trust&nbsp;
            Powered by <a href="https://gohugo.io" target="_blank">Hugo</a> with theme <a href="https://github.com/carsonip/hugo-theme-minos">Minos</a>
        </div>
    </div>
    

    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.9.0/styles/tomorrow-night.min.css" integrity="sha256-2wL88NKUqvJi/ExflDzkzUumjUM73mcK2gBvBBeLvTk=" crossorigin="anonymous" />
    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.9.0/highlight.min.js" integrity="sha256-KbfTjB0WZ8vvXngdpJGY3Yp3xKk+tttbqClO11anCIU=" crossorigin="anonymous"></script>
    <script>hljs.initHighlightingOnLoad();</script>

    
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.7.1/katex.min.css" integrity="sha384-wITovz90syo1dJWVh32uuETPVEtGigN07tkttEqPv+uR2SE/mbQcG7ATL28aI9H0" crossorigin="anonymous">
        <script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.7.1/katex.min.js" integrity="sha384-/y1Nn9+QQAipbNQWU65krzJralCnuOasHncUFXGkdwntGeSvQicrYkiUBwsgUqc1" crossorigin="anonymous"></script>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.7.1/contrib/auto-render.min.js" integrity="sha256-ExtbCSBuYA7kq1Pz362ibde9nnsHYPt6JxuxYeZbU+c=" crossorigin="anonymous"></script>
        <script>renderMathInElement(document.body);</script>
    
    <script>
        document.getElementById('main-nav-toggle').addEventListener('click', function () {
            var header = document.getElementById('header');
            if (header.classList.contains('mobile-on')) {
                header.classList.remove('mobile-on');
            } else {
                header.classList.add('mobile-on');
            }
        });
    </script>
</footer>
</div>
</body>
</html>
